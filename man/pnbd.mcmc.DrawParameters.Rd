% Generated by roxygen2 (4.0.0): do not edit by hand
\name{pnbd.mcmc.DrawParameters}
\alias{pnbd.mcmc.DrawParameters}
\title{Hierarchical Bayes variant of Pareto/NBD}
\usage{
pnbd.mcmc.DrawParameters(data, mcmc = 10000, burnin = 0, thin = 1,
  chains = 1, use_data_augmentation = TRUE, param_init = list(r = 1, alpha
  = 1, s = 1, beta = 1), hyper_prior = list(r_1 = 1/1000, r_2 = 1/1000,
  alpha_1 = 1/1000, alpha_2 = 1/1000, s_1 = 1/1000, s_2 = 1/1000, beta_1 =
  1/1000, beta_2 = 1/1000))
}
\arguments{
\item{data}{data.frame with columns 'x', 't.x', 'T.cal'}

\item{mcmc}{number of MCMC steps}

\item{burnin}{number of initial MCMC steps which are discarded}

\item{thin}{only every thin-th MCMC step will be returned}

\item{chains}{number of MCMC chains to be run}

\item{use_data_augmentation}{determines MCMC method to be used}

\item{param_init}{list of 2nd-level parameter start values}

\item{hyper_prior}{list of hyper parameters for 2nd-level parameters}
}
\value{
2-element list
level_1:  list of coda::mcmc.list objects; one for each customer, containing individual-level draws
level_2:  coda::mcmc.list object containing draws of heterogeneity parameters
}
\description{
\code{pnbd.mcmc.DrawParameters} samples parameters via MCMC for a given CBS
matrix
}
\details{
method 1) If \code{use_data_augmentation==TRUE} then implementation follows chapter
3.2 of Sandeep Conoor's dissertation
http://gradworks.umi.com/34/02/3402149.html, i.e. parameter space is expanded
with unobserved lifetime tau_i. Note, however, that  we follow the notation
of original SMC paper with alpha and beta being the 'rate' parameters of the
Gamma distributions, instead of 'scale' parameter.

method 2) If \code{use_data_augmentation==FALSE} then implementation follows
Shao-Hui Ma & Jin-Lan Liu paper
http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4344404, i.e. no data
augmentation and draws on individual level need to be done via slice
sampling. As such it is 10x slower than method 1)

Estimating parameters via Pareto/NBD MCMC can be 10x slower than Pareto/NBD
MLE, which itself can be 10x slower than BG/NBD. Both methods exhibit highly
autocorrelated draws of {r, alpha, s, beta} and hence need to be run long, to
generate 'enough' draws
}
\examples{
#params <- list(r=1.4, alpha=1.3, s=0.7, beta=7)
#cbs <- pcnbd.GenerateData(1000, 10, 5, params)$cbs
#draws <- pnbd.mcmc.DrawParameters(cbs, mcmc=10000, burnin=10000, thin=10, chains=2)
#plot(draws$level_2)
#rbind("actual"=unlist(params), "estimated"=summary(draws$level_2, quantiles=0.5)$quantiles)
}
\references{
http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4344404

http://gradworks.umi.com/34/02/3402149.html
}
\seealso{
pcnbd.GenerateData
}

